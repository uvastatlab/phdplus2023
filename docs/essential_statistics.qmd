---
title: "Essential Statistics"
author: "Clay Ford, UVA Library"
format:
  revealjs:
    embed-resources: true
    smaller: true
---

```{r echo=FALSE}
d <- readRDS("../data/albemarle_homes_2023.rds")
# d <- readRDS("data/albemarle_homes_2023.rds")
```

## Data Literacy

> data literacy...describes the ability to not only carry out statistical analysis on real world problems, but also to understand and critique any conclusions drawn by others on the basis of statistics.

David Spiegelhalter, *The Art of Statistics*

## Agenda

In this session we explore using R to carry out and interpret basic statistical analyses and highlight potential sources of statistical errors.

-   Proportions
-   Means and Medians
-   Uncertainty
-   Modeling

## Hold the bacon?

In 2015 the World Health Organization (WHO) [announced](https://www.who.int/news-room/questions-and-answers/item/cancer-carcinogenicity-of-the-consumption-of-red-meat-and-processed-meat) that eating 50g of processed meat a day was associated with an increased risk of bowel cancer of 18%.

How concerned should we be?

It depends. Is that an *absolute* increase or a *relative* increase?

## Absolute versus Relative

-   Absolute is additive.
    -   2% + 18% = 20% (increase 18%)
    -   20% + -18% = 2% (decrease 18%)
-   Relative is multiplicative.
    -   2% x (1 + 0.18) 1.18 = 2.36% (increase 18%)
    -   20% x (1 - 0.18) 0.82 = 16.4% (decrease 18%)

The 18% increase mentioned in the WHO study is *relative*.

If the risk (probability) of bowel cancer without consuming 50g of processed meat per day is 0.001, then an 18% increase raises the risk to 0.001 x 1.18 = 0.00118.

::: callout-important
Interpreting a relative increase as absolute can make it seem more important than it really is.
:::

## Determining change

Given two proportions or percents...

-   use subtraction to determine **absolute** change
-   division (or a ratio) to determine **relative** change

Example: In 2014, 0.0694, or 6.94%, of U.S. households had at least one motorcycle. In 2018, that figure rose to 0.0802, or 8.02%. [source](https://www.prnewswire.com/news-releases/us-households-with-a-motorcycle-climbs-to-record-8-percent-in-2018-300783120.html)

**Absolute change**:\
Ownership increased by 8.02% - 6.94% = 1.08%\
The percentage of households increased from 6.94% to 8.02%

**Relative change**:\
Ownership increased by 8.02/6.94 = 1.1556 = 15.56%\
The 2014 percentage increased by 15.56%

## Proportions versus Percents

Proportions range from 0 to 1. (eg, 0.18)

Percents are proportions multiplied by 100 with a % sign appended to the value. (0.18 x 100 = 18%)

Most any statistical program is going to return *proportions*.

::: callout-important
Beware of confusing proportions with percents. Example: confusing a percent risk of 0.5% as a proportion (probability) of 0.5 (instead of 0.005)
:::

::: callout-important
Beware of importing data with percents into R. The percent symbols can result in numbers being treated as character data.
:::

## Don't forget the denominator

When used to summarize data, Percents and Proportions are both relative to the size of the data, which is in the denominator.

Example: 0.14, or 14%, of students surveyed said they were cancelling Netflix.

That could be 1/7, or 100/700. The former seems less important because of the small denominator.

Percents and Proportions presented without the raw values used to calculate them should be treated carefully.

## Probability versus Odds

Probabilities (p) range from 0 to 1.

Odds = p/(1 - p) and range from 0 to infinity.

If the probability of rain tomorrow is 0.2, the odds are 0.2/(1 - 0.2) = 1/4.

If the probability of rain tomorrow is 0.8, the odds are 0.8/(1 - 0.) = 4.

::: callout-important
Beware of expressing probabilities as odds and vice versa.
:::

## Proportions in R

```{r echo=TRUE}
xtabs(~ cooling + fp, data = d) # cross tabulation of cooling and fp
```

Proportion of homes with/without fireplaces by cooling

```{r echo=TRUE}
xtabs(~ cooling + fp, data = d) |>
  proportions(margin = 1) |>  # by rows
  round(3)
```

Proportion of homes with/without cooling by fp

```{r echo=TRUE}
xtabs(~ cooling + fp, data = d) |>
  proportions(margin = 2) |>  # by columns
  round(3)
```

Let's go to R.

## Our brains can't handle this

```{r echo=TRUE}
head(d$totalvalue, n = 200)
```

## Center and Spread

We usually summarize numeric data by calculating some measure of the center and the spread.

-   *Center* is usually interpreted as the most representative value.
-   *Spread* is usually interpreted as how far away we can expect any value to be from the center value.

The most common measures of center are the **mean** and **median**.

The most common measures of spread are the **standard deviation (SD)** and **interquartile range (IQR)**.

## Mean and Median

The mean is the point at which the data would balance on a fulcrum.

The median is the middle point of data sorted in ascending order.

When data are *symmetric*, the mean and median are close.

When data are *skewed*, the median tends to be a better measure of center or typical value.

::: callout-tip
In practice you should *examine both* if planning to present a summary of data.
:::

## Some distributions

[Mean]{style="color:red;"} and [Median]{style="color:blue;"}

```{r}
f <- function(x){
  # points(x = mean(x), y = -5, pch = 17, col = "red")
  abline(v = mean(x), col = "red")
  # points(x = median(x), y = -5, pch = 17, col = "blue")
  abline(v = median(x), col = "blue")
}
set.seed(2)
n <- 500
y1 <- rnorm(n)
y2 <- rexp(n)
x <- sample(0:1, replace = T, size = n)
y3 <- ifelse(x == 1, rnorm(n,5,1), rnorm(n,11,2))
y4 <- runif(n)

op <- par(mfrow = c(2,2), mar = c(2, 4, 2, 2) + 0.1)
hist(y1, main = "symmetric", xlab = "", ylab = "")
f(x = y1)
hist(y2, main = "skewed", xlab = "", ylab = "")
f(x = y2)
hist(y3, main = "bimodal", xlab = "", ylab = "")
f(x = y3)
hist(y4, main = "symmetric", xlab = "", ylab = "")
f(x = y4)
par(op)
```

## The `summary()` function

The `summary()` function when used with a numeric vector (or column) of data returns 6 values.

1.  The smallest value
2.  The 25th percentile (value below which lies 25% of the data)
3.  The median (the 50th percentile)
4.  The mean
5.  The 75th percentile (value below which lies 25% of the data)
6.  The largest value

```{r echo=TRUE}
summary(d$totalvalue)
```

It appears the data is skewed *right* since the mean is larger than the median by about \$100,000. A histogram and the `summary()` function can tell you a lot about your data.

## Standard Deviation and IQR

Standard Deviation is really only appropriate for symmetric data. Like the mean, it can be easily influenced by extreme values.

IQR is the difference between the 75th and 25th percentiles. It contains the middle 50% of the data. It is unaffected by extreme values.

```{r echo=TRUE}
sd(d$totalvalue)
IQR(d$totalvalue)
```

As summaries of data, they can be confusing if your audience is not familiar with the concept of *spread*.

## Summarizing two sets of values

Below is a scatterplot of 200 randomly sampled homes from Albemarle County comparing total value to finished sq ft. How can we summarize this relationship?

```{r}
set.seed(23)
i <- sample(nrow(d), size = 200)
samp_d <- d[i,]
plot(totalvalue ~ finsqft, data = samp_d)
```

## Correlation

Correlation is a single value that can (sometimes) summarize a relationship between two sets of numeric data.

Correlation is unitless and ranges from -1 to 1. It expresses how close dots fall along a straight line.

**Pearson** correlation measures linear association.\
**Spearman** *rank* correlation can measure non-linear association such as curved lines.

The correlation of the data in the previous plot can be calculated as follows:

```{r echo=TRUE}
cor(samp_d$finsqft, samp_d$totalvalue, method = "pearson")
cor(samp_d$finsqft, samp_d$totalvalue, method = "spearman")
```

## Correlation warning

Correlations near 0 do not mean there is no relationship. Observe the following, courtesy of [The Datasaurus Dozen](https://github.com/jumpingrivers/datasauRus). Lesson: plot your data. Let's go to R!

```{r}
library(datasauRus)
dat <- datasaurus_dozen_wide
op <- par(mfrow = c(1,2), pty = "s")
plot(slant_down_y ~ slant_down_x, data = dat, xlab = "", ylab = "")
plot(dino_y ~ dino_x, data = dat, xlab = "", ylab = "")
par(op)
```

```{r echo=TRUE}
cor(dat$slant_down_x, dat$slant_down_y) # slanting lines
cor(dat$dino_x, dat$dino_y)  # t-rex

```


## Trees

> "we estimate that the global number of trees is approximately 3.04 trillion (+/-0.096 trillion, 95% confidence intervals (CI))"

Mapping tree density at a global scale, [Nature](https://www.nature.com/articles/nature14967) (2015)

## Uncertainty

Sometimes we can collect all the data in a population (eg, Albemarle County real estate data). The mean of the data is the mean. There is no uncertainty. 

Most of the time we can only collect a sample (eg, voters, trees, cows). The mean of the sample data is _not_ the mean of the entire population. It is an estimate.

We often use the estimate as our best guess at the population mean. How uncertain is this estimate?

This is usually answered with _standard errors_ and _confidence intervals_.

## Standard Errors

Imagine randomly sampling 30 UVA students, weighing their backbacks, and taking the mean weight. And then sampling 30 more students and getting another mean. And again, and again, thousands of times, getting more means.

Now calculate the standard deviation of those means. That's the _standard error_.

The spread of the sample means summarizes the uncertainty of our sample mean.

In practice, we don't take thousands of means. We take one and we usually calculate standard error using a formula such as $sd/\sqrt{n}$.

For example, a [study](https://www.sciencedirect.com/science/article/pii/S2314853516300555) estimated the mean weight of chicken eggs to be about 55.02 with a standard error of 0.40 when the chicken was 25 weeks old. 

::: callout-important
Be cautious of interpreting sample statistics presented without standard errors.  
:::

## Confidence Intervals

Adding and subtracting standard errors to our estimate forms an interval of what we might say is a reasonable range of the true population value.

The most common interval calculated is the _95% confidence interval_ (CI).

We say "95%" because the method should work 95% of the time based on how many standard errors we use to create the interval.

We call it "confidence" because we are confident in the method. 

If we were to take thousands of samples and calculate thousands of 95% confidence intervals, about 95% of the intervals should contain the true value. 

The 95% confidence interval on the number of trees (in trillions) was [2.94, 3.14]. That interval either contains the true number or it does not. 

::: callout-important
A confidence interval is _not_ a probability interval. Do not say there is a 95% probability the value is between the lower and upper bounds.
:::

## Cow painting

> Painting 'Zebra Stripes' on Cows Wards Off Biting Flies [source](https://www.realclearscience.com/quick_and_clear_science/2019/10/07/painting_zebra_stripes_on_cows_wards_off_biting_flies.html)

> "The total numbers of biting flies on the legs and body for B&W cows were almost half those on Control (p < 0.0001)." [paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0223447)

What does "p < 0.0001" mean?

## Hypothesis testing and p-values

Let's say we believe a coin is fair and lands heads 50% of the time.

We flip it 20 times and get 18 heads. That's 18/20 = 90%.

If the coin was really fair, what is the probability of getting 18 or more heads?

The answer is about 0.0002. That's a _p-value_.

That's a small probability and leads us to reject the belief that the coin is fair.

What we just described is an example of a _hypothesis test_.


## Hypothesis testing and p-values

Hypothesis testing estimates the probability of obtaining the data we collected under the assumption of some hypothesis, usually null, or no effect, hypothesis.

What is the probability a cow painted like a zebra would have less fly bites than an unpainted cow, _assuming the paint job had no effect_? The authors state p < 0.0001.

Historically p-values < 0.05 have been interpreted as "statistically significant".

::: callout-tip
When you see a p-value, think "probability of the data, or more extreme data, assuming a null hypothesis was true."
:::


## p-values are slippery

P-values are often misinterpreted and misused.

1. They _do not_ measure the probability the null hypothesis is true or that the data were produced by random chance alone.
2. They _do not_ justify proof of something because they're less than 0.05.
3. They _do not_ prove the null hypothesis because they're greater than 0.05.
4. They _do not_ measure the size of an effect or the importance of a result.

See The American Statistical Association's [special issue](https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913) on p-values. 
P-values are just another measure. It should not be revered as the final word in any analysis. 

## Differences

## General ideas

-   Be aware of what a statistic leaves out:
    -   a mean doesn't tell you the range or the size of the data
    -   a percent increase doesn't tell you the raw values

## References

Why I Don't Like Percents\
https://www.fharrell.com/post/percent/

Statistics Notes: What is a percentage difference?\
https://www.bmj.com/content/358/bmj.j3663
