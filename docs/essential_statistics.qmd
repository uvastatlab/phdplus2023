---
title: "Essential Statistics"
author: "Clay Ford, UVA Library"
format:
  revealjs:
    embed-resources: true
    smaller: true
---

## Data Literacy

```{r echo=FALSE}
d <- readRDS("../data/albemarle_homes_2023.rds")
# d <- readRDS("data/albemarle_homes_2023.rds")
```

> data literacy...describes the ability to not only carry out statistical analysis on real world problems, but also to understand and critique any conclusions drawn by others on the basis of statistics.

David Spiegelhalter, *The Art of Statistics*

## Agenda

In this session we explore using R to carry out and interpret basic statistical analyses and highlight potential sources of statistical errors.

-   Proportions and Percents
-   Summarizing Numeric Data
-   Uncertainty
-   Hypothesis testing 
-   Modeling

## Hold the bacon?

In 2015 the World Health Organization (WHO) [announced](https://www.who.int/news-room/questions-and-answers/item/cancer-carcinogenicity-of-the-consumption-of-red-meat-and-processed-meat) that eating 50g of processed meat a day was associated with an increased risk of bowel cancer of 18%.

How concerned should we be?

It depends. Is that an *absolute* increase or a *relative* increase?

## Absolute versus Relative

-   Absolute is additive.
    -   2% + 18% = 20% (increase 18%)
    -   20% + -18% = 2% (decrease 18%)
-   Relative is multiplicative.
    -   2% x (1 + 0.18) 1.18 = 2.36% (increase 18%)
    -   20% x (1 - 0.18) 0.82 = 16.4% (decrease 18%)

The 18% increase mentioned in the WHO study is *relative*.

If the risk (probability) of bowel cancer without consuming 50g of processed meat per day is 0.001, then an 18% increase raises the risk to 0.001 x 1.18 = 0.00118.

::: callout-important
Interpreting a relative increase as absolute can make it seem more important than it really is.
:::

## Determining change

Given two proportions or percents...

-   use subtraction to determine **absolute** change
-   division (or a ratio) to determine **relative** change

Example: In 2014, 0.0694, or 6.94%, of U.S. households had at least one motorcycle. In 2018, that figure rose to 0.0802, or 8.02%. [source](https://www.prnewswire.com/news-releases/us-households-with-a-motorcycle-climbs-to-record-8-percent-in-2018-300783120.html)

**Absolute change**:\
Ownership increased by 8.02% - 6.94% = 1.08%\
The percentage of households increased from 6.94% to 8.02%

**Relative change**:\
Ownership increased by 8.02/6.94 = 1.1556 = 15.56%\
The 2014 percentage increased by 15.56%

## Proportions versus Percents

Proportions range from 0 to 1. (eg, 0.18)

Percents are proportions multiplied by 100 with a % sign appended to the value. (0.18 x 100 = 18%)

Most any statistical program is going to return *proportions*.

::: callout-important
Beware of confusing proportions with percents. Example: confusing a percent risk of 0.5% as a proportion (probability) of 0.5 (instead of 0.005)
:::

::: callout-important
Beware of importing data with percents into R. The percent symbols can result in numbers being treated as character data.
:::

## Don't forget the denominator

When used to summarize data, Percents and Proportions are both relative to the size of the data, which is in the denominator.

Example: 0.14, or 14%, of students surveyed said they were cancelling Netflix.

That could be 1/7, or 100/700. The former seems less important because of the small denominator.

::: callout-tip
Beware of percents and proportions presented without the sample size used to calculate them.
:::

## Probability versus Odds

Probabilities (p) range from 0 to 1.

Odds = p/(1 - p) and range from 0 to infinity.

If the probability of rain tomorrow is 0.2, the odds are 0.2/(1 - 0.2) = 1/4.

If the probability of rain tomorrow is 0.8, the odds are 0.8/(1 - 0.8) = 4.

::: callout-important
Beware of expressing or interpreting probabilities as odds and vice versa.
:::

Let's go to R.



## Our brains can't handle this

```{r echo=TRUE}
head(d$totalvalue, n = 200)
```

## Center and Spread

We usually summarize numeric data by calculating some measure of the center and the spread.

-   *Center* is usually interpreted as the most representative value.
-   *Spread* is usually interpreted as how far away we can expect any value to be from the center value.

The most common measures of center are the **mean** and **median**.

The most common measures of spread are the **standard deviation (SD)** and **interquartile range (IQR)**.

## Mean and Median

The mean is the point at which the data would balance on a fulcrum.

The median is the middle point of data sorted in ascending order.

When data are *symmetric*, the mean and median are close.

When data are *skewed*, the median tends to be a better measure of center or typical value.

::: callout-tip
In practice you should *examine both* if planning to present a summary of data.
:::

## Some distributions

[Mean]{style="color:red;"} and [Median]{style="color:blue;"}

```{r}
f <- function(x){
  # points(x = mean(x), y = -5, pch = 17, col = "red")
  abline(v = mean(x), col = "red")
  # points(x = median(x), y = -5, pch = 17, col = "blue")
  abline(v = median(x), col = "blue")
}
set.seed(2)
n <- 500
y1 <- rnorm(n)
y2 <- rexp(n)
x <- sample(0:1, replace = T, size = n)
y3 <- ifelse(x == 1, rnorm(n,5,1), rnorm(n,11,2))
y4 <- runif(n)

op <- par(mfrow = c(2,2), mar = c(2, 4, 2, 2) + 0.1)
hist(y1, main = "symmetric", xlab = "", ylab = "")
f(x = y1)
hist(y2, main = "skewed", xlab = "", ylab = "")
f(x = y2)
hist(y3, main = "bimodal", xlab = "", ylab = "")
f(x = y3)
hist(y4, main = "symmetric", xlab = "", ylab = "")
f(x = y4)
par(op)
```

## The `summary()` function

The `summary()` function when used with a numeric vector (or column) of data returns 6 values (7 if you have missing data):

1.  The smallest value
2.  The 25th percentile (value below which lies 25% of the data)
3.  The median (the 50th percentile)
4.  The mean
5.  The 75th percentile (value below which lies 75% of the data)
6.  The largest value

```{r echo=TRUE}
summary(d$lastsaleprice)
```

It appears the data is skewed *right* since the mean is larger than the median. A histogram and the `summary()` function can tell you a lot about your data.

## Standard Deviation and IQR

Standard Deviation is really only appropriate for symmetric data. Like the mean, it can be easily influenced by extreme values.

IQR is the difference between the 75th and 25th percentiles. It contains the middle 50% of the data. It is unaffected by extreme values.

```{r echo=TRUE}
sd(d$totalvalue)
IQR(d$totalvalue)
```

As summaries of data, they can be confusing if your audience is not familiar with the concept of *spread*.

## Transforming data

Transforming data to a different scale can reduce the impact of extreme values. A common transformation is the _log_ transformation.

This basically translates data into _magnitudes_.

```{r echo=TRUE}
x <- c(10, 100, 1000, 10000, 100000, 1000000)
log10(x) # what power do we raise 10 to get x?
log(x) # what power do we raise e to get x?
```

Natural logs are often preferred in statistical analyses because they can make interpretation easier. 

They are also appropriate when large data values can be assumed to be bigger in a _relative_ sense rather than an _absolute_ sense. 

## Before and After

Notice how total value goes from ranging from 4200 - 8,000,000 to about 10 - 16.

```{r}
op <- par(mfrow = c(1,2), pty = "s")
hist(d$totalvalue)
hist(log(d$totalvalue))
par(op)
```

::: callout-tip
Log transformations only work for positive data.
:::

## Summarizing two sets of values

Below is a scatterplot of 200 randomly sampled homes from Albemarle County comparing total value to finished sq ft. How can we summarize this relationship?

```{r}
set.seed(23)
i <- sample(nrow(d), size = 200)
samp_d <- d[i,]
plot(totalvalue ~ finsqft, data = samp_d)
```

## Correlation

Correlation is a single value that can (sometimes) summarize a relationship between two sets of numeric data.

Correlation is unitless and ranges from -1 to 1. It expresses how close dots fall along a straight line. [Wikipedia illustration](https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg)

**Pearson** correlation measures linear association.\
**Spearman** *rank* correlation can measure non-linear association such as curved lines.

The correlation of the data in the previous plot can be calculated as follows:

```{r echo=TRUE}
cor(samp_d$finsqft, samp_d$totalvalue, method = "pearson")
cor(samp_d$finsqft, samp_d$totalvalue, method = "spearman")
```

## Correlation warning

Correlations near 0 do not mean there is no relationship. Observe the following, courtesy of [The Datasaurus Dozen](https://github.com/jumpingrivers/datasauRus). Lesson: plot your data. Let's go to R!

```{r}
library(datasauRus)
dat <- datasaurus_dozen_wide
op <- par(mfrow = c(1,2), pty = "s")
plot(slant_down_y ~ slant_down_x, data = dat, xlab = "", ylab = "")
plot(dino_y ~ dino_x, data = dat, xlab = "", ylab = "")
par(op)
```

```{r echo=TRUE}
cor(dat$slant_down_x, dat$slant_down_y) # slanting lines
cor(dat$dino_x, dat$dino_y)  # t-rex

```



## Trees

> "we estimate that the global number of trees is approximately 3.04 trillion (+/-0.096 trillion, 95% confidence intervals (CI))"

Mapping tree density at a global scale, [Nature](https://www.nature.com/articles/nature14967) (2015)

## Uncertainty

Sometimes we can collect all the data in a population (eg, Albemarle County real estate data). The mean of the data is the mean. There is no uncertainty. 

Most of the time we can only collect a sample (eg, voters, trees, cows). The mean of the sample data is _not_ the mean of the entire population. It is an _estimate_.

We often use the estimate as our best guess at the population mean. How uncertain is this estimate?

This is usually answered with _standard errors_ and _confidence intervals_.

## Standard Errors

Imagine randomly sampling 30 UVA students, weighing their backbacks, and taking the mean weight. And then sampling 30 more students and getting another mean. And again, and again, thousands of times, getting more means.

Now calculate the standard deviation of those means. That's the _standard error_.

The spread of the sample means summarizes the uncertainty of our sample mean.

In practice, we don't take thousands of means. We take one and we usually calculate standard error using a formula such as $sd/\sqrt{n}$.

For example, a [study](https://www.sciencedirect.com/science/article/pii/S2314853516300555) estimated the mean weight of chicken eggs to be about 55.02g with a standard error of 0.40 when the chicken was 25 weeks old. 

::: callout-important
Be cautious of interpreting estimates presented without standard errors.  
:::

## Confidence Intervals

Adding and subtracting standard errors to our estimate forms an interval of what we might say is a reasonable range of the true population value.

The most common interval calculated is the _95% confidence interval_ (CI).

We say "95%" because the method should work 95% of the time based on how many standard errors we add/subtract to create interval.

We call it "confidence" because we are confident in the method. 

## Confident in the process

If we were to take thousands of samples and calculate thousands of 95% confidence intervals, about 95% of the intervals should contain the true value. 

The 95% confidence interval on the number of trees (in trillions) was [2.94, 3.14]. That interval either contains the true number or it does not. 

::: callout-important
A confidence interval is _not_ a probability interval. Do not say there is a 95% probability the value is between the lower and upper bounds.
:::

Let's go to R.

## Cow painting

> "The total numbers of biting flies on the legs and body for B&W cows were almost half those on Control (p < 0.0001)." [paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0223447)

Painting 'Zebra Stripes' on Cows Wards Off Biting Flies [source](https://www.realclearscience.com/quick_and_clear_science/2019/10/07/painting_zebra_stripes_on_cows_wards_off_biting_flies.html)

What does "p < 0.0001" mean?

![](../images/zebra_cow.jpg){fig-alt="cow painted like zebra." fig-align="right"}

## Hypothesis testing and p-values

Let's say we believe a coin is fair and lands heads 50% of the time.

We flip it 20 times and get 18 heads. That's 18/20 = 90%.

If the coin was really fair, what is the probability of getting 18 or more heads?

The answer is about 0.0002. That's a _p-value_.

That's a small probability and leads us to reject the belief that the coin is fair.

What we just described is an example of a _hypothesis test_.


## Hypothesis testing and p-values

Hypothesis testing estimates the probability of obtaining the data we collected under the assumption of some hypothesis, usually null, or no effect, hypothesis.

What is the probability a cow painted like a zebra would have less fly bites than an unpainted cow, _assuming the paint job had no effect_? The authors state p < 0.0001.

Historically p-values < 0.05 have been interpreted as "statistically significant".

::: callout-tip
When you see a p-value, think "probability of the data, or more extreme data, assuming a null hypothesis was true."
:::


## p-values are slippery

P-values are often misinterpreted and misused.

1. They _do not_ measure the probability the null hypothesis is true or that the data were produced by random chance alone.
2. They _do not_ justify proof of something because they're less than 0.05.
3. They _do not_ prove the null hypothesis because they're greater than 0.05.
4. They _do not_ measure the size of an effect or the importance of a result.

See The American Statistical Association's [special issue](https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913) on p-values. 

::: callout-important
P-values should not be revered as the final word in any analysis. 
::: 

Let's go to R.


## Is education risky?

> Women with ≥3 years university education had increased risk of glioma (1.23, 1.08 to 1.40) and meningioma (1.16, 1.04 to 1.29) compared to those with primary education.

> Poisson regression models were used to calculate incidence rate ratios (IRR) for brain tumours by different indicators of socioeconomic position (SEP), with adjustment for potential confounders.

Socioeconomic position and the risk of brain tumour: a Swedish national population-based cohort study [source](https://jech.bmj.com/content/70/12/1222)

What do they mean by _with adjustment for potential confounders_?

## Conditional means

The mean total value value of Albemarle homes is a little over \$500,000.

```{r echo=TRUE}
mean(d$totalvalue)
```

But the mean total value of Albemarle homes when they have 1,280 finished square is much lower.

```{r echo=TRUE}
mean(d$totalvalue[d$finsqft == 1280])
```

But the mean total value of Albemarle homes when they have 1,280 finished square and they have central air is a little higher.

```{r echo=TRUE}
mean(d$totalvalue[d$finsqft == 1280 & d$cooling == "Central Air"])
```

The expected value of a home appears to depend on certain features.

## Linear Models

A _linear model_ allows us to estimate expected values conditional on features or predictors.

A linear model is a function of predictors. For example, here's a simple model:

$$\text{total value} = 80,839 + 111\text{ finsqft} + 49,396 \text{ cooling}$$ 

Setting finsqft = 2000 and cooling = 1 (central air) returns:

$$\text{total value} = 80,839 + 111(2000) + 49,396(1) = \$ 352,235$$ 

It says each additional finished square foot adds \$111 to the expected value of a home. It also says a home with central air is expected to be worth almost \$50,000 than a home without central air. **This may not be a good model!**

## No model is perfect

A linear model attempts to _approximate_ the process that generated the data. It will always be wrong and uncertain, but hopefully it will be useful.

We pick the model. 

If we are satisfied with the model, we can use it to make predictions or summarize associations. 

This is also referred to as _Multiple Regression_ or _Regression Modeling_.

## Sources of uncertainty

Consider this model again:

$$\text{total value} = 80,839 + 111\text{ finsqft} + 49,396 \text{ cooling}$$ 

- The model may be bad. 
- The _coefficients_ (80839, 111 and 49396) are uncertain.
- A few homes may be unduly influencing how these coefficients are estimated.
- Predicted total values are uncertain.


## Building linear models 

R is exceptionally good for building linear models. Perhaps too good.

> "A computer lets you make more mistakes faster than any other invention with the possible exceptions of handguns and Tequila." -Mitch Ratcliffe 

Building linear models in R is rather easy. Picking which predictors to include, specifying the model, and evaluating model performance is much harder.



## References

The Art of Statistics

Why I Don't Like Percents\
https://www.fharrell.com/post/percent/

Statistics Notes: What is a percentage difference?\
https://www.bmj.com/content/358/bmj.j3663
